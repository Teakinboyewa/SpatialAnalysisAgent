{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7405086b-b272-436c-9345-9013e9ab640a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install pyvisa\n",
    "# ! pip install toml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "464945e2-5830-4a1e-bd2e-bc3dc96c5ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os    \n",
    "import sys    \n",
    "import time\n",
    "import pprint\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615e5f74-beb5-4adf-ad91-58fb3bfe41f1",
   "metadata": {},
   "source": [
    "# QGIS help page crawler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20cda53f-1c2b-4110-b2ed-f6a8dc388876",
   "metadata": {},
   "source": [
    "## How to use?\n",
    "1. Update the `url` variable using the links in [https://docs.qgis.org/3.34/en/docs/user_manual/processing_algs/index.html](https://docs.qgis.org/3.34/en/docs/user_manual/processing_algs/index.html), e.g., [https://docs.qgis.org/3.34/en/docs/user_manual/processing_algs/qgis/rasteranalysis.html](https://docs.qgis.org/3.34/en/docs/user_manual/processing_algs/qgis/rasteranalysis.html).\n",
    "2. Run the program. \n",
    "\n",
    "**Please check the results manually to ensure they are correct!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c3bba44-f053-4f0a-aed4-da775996bd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import toml\n",
    "import os\n",
    "import re \n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "729fc5cf-fee8-4976-932c-9bdc1955ea21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.1.23. Vector overlay — QGIS Documentation  documentation\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "##### These urls were processed.\n",
    "# url = \"https://docs.qgis.org/3.34/en/docs/user_manual/processing_algs/qgis/rasteranalysis.html\"\n",
    "# there are 156 sections, and 33 sections have h2 tag, while 31 tool sections.\n",
    "\n",
    "# url = \"https://docs.qgis.org/3.34/en/docs/user_manual/processing_algs/qgis/interpolation.html\"\n",
    "# url = \"https://docs.qgis.org/3.34/en/docs/user_manual/processing_algs/qgis/vectoranalysis.html\"\n",
    "# url = \"https://docs.qgis.org/3.34/en/docs/user_manual/processing_algs/qgis/vectorgeneral.html\"\n",
    "# url = \"https://docs.qgis.org/3.34/en/docs/user_manual/processing_algs/qgis/vectorgeometry.html\"\n",
    "# url = \"https://docs.qgis.org/3.34/en/docs/user_manual/processing_algs/gdal/rasteranalysis.html\"\n",
    "# url = \"https://docs.qgis.org/3.34/en/docs/user_manual/processing_algs/qgis/plots.html\"\n",
    "# url = \"https://docs.qgis.org/3.34/en/docs/user_manual/processing_algs/qgis/rasterterrainanalysis.html\"\n",
    "url = \"https://docs.qgis.org/3.34/en/docs/user_manual/processing_algs/qgis/vectoroverlay.html\"\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    html_content = response.content\n",
    "    # Parse the HTML content using BeautifulSoup\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    \n",
    "    # Now you can work with 'soup' to extract the relevant sections\n",
    "    # Example: printing the title of the page\n",
    "    print(soup.title.get_text())\n",
    " \n",
    "else:\n",
    "    print(f\"Failed to retrieve the page. Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e84a6df-f70f-4c72-8315-89411fe6eb51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_sections = soup.find_all('section')\n",
    "len(raw_sections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "065e8e84-a57b-4fc4-9803-51eb3fed2532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for idx, section in enumerate(sections):\n",
    "    # print(idx)\n",
    "    # print(section)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cc07ac1-e636-4f1e-bdaf-452f54bb6253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 Section with ID 'None' contains an <h3> tag: '28.1.23.1. Clip'\n",
      "1 2 Section with ID 'vector-overlay' contains an <h3> tag: '28.1.23.1. Clip'\n",
      "2 3 Section with ID 'clip' contains an <h3> tag: '28.1.23.1. Clip'\n",
      "6 4 Section with ID 'difference' contains an <h3> tag: '28.1.23.2. Difference'\n",
      "12 5 Section with ID 'difference-multiple' contains an <h3> tag: '28.1.23.3. Difference (multiple)'\n",
      "16 6 Section with ID 'extract-clip-by-extent' contains an <h3> tag: '28.1.23.4. Extract/clip by extent'\n",
      "20 7 Section with ID 'intersection' contains an <h3> tag: '28.1.23.5. Intersection'\n",
      "26 8 Section with ID 'intersection-multiple' contains an <h3> tag: '28.1.23.6. Intersection (multiple)'\n",
      "32 9 Section with ID 'line-intersections' contains an <h3> tag: '28.1.23.7. Line intersections'\n",
      "38 10 Section with ID 'split-with-lines' contains an <h3> tag: '28.1.23.8. Split with lines'\n",
      "42 11 Section with ID 'symmetrical-difference' contains an <h3> tag: '28.1.23.9. Symmetrical difference'\n",
      "48 12 Section with ID 'union' contains an <h3> tag: '28.1.23.10. Union'\n",
      "54 13 Section with ID 'union-multiple' contains an <h3> tag: '28.1.23.11. Union (multiple)'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt = 0\n",
    "sections = []\n",
    "for idx, section in enumerate(raw_sections):\n",
    "     \n",
    "    section_id = section.get('id')  # Extract the section ID\n",
    "    tag = section.find('h2')  # Try to find an <h3> tag in the section\n",
    "    # print(tag)\n",
    "    if tag:\n",
    "        cnt += 1\n",
    "        print(idx, cnt, f\"Section with ID '{section_id}' contains an <h3> tag: '{tag.get_text()}'\")\n",
    "        # cnt += 1\n",
    "        sections.append(section)\n",
    "    else:\n",
    "        # print(idx, f\"Section with ID '{section_id}' does not contain an <h3> tag.\")\n",
    "        pass\n",
    "len(sections)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84abdfe5-b191-4f7d-aa31-8c3f483e2345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 tool_name: qgis_clip\n",
      "2 tool_name: qgis_difference\n",
      "3 tool_name: qgis_multidifference\n",
      "4 tool_name: qgis_extractbyextent\n",
      "5 tool_name: qgis_intersection\n",
      "6 tool_name: qgis_multiintersection\n",
      "7 tool_name: qgis_lineintersections\n",
      "8 tool_name: qgis_splitwithlines\n",
      "9 tool_name: qgis_symmetricaldifference\n",
      "10 tool_name: qgis_union\n",
      "11 tool_name: qgis_multiunion\n"
     ]
    }
   ],
   "source": [
    "def get_section_by_heading(section, level, heading):        \n",
    "    tags = section.find_all(level)\n",
    "    for tag in tags:\n",
    "        if heading in tag.get_text():\n",
    "            section_tag = tag.find_parent('section')\n",
    "            # print(section_tag.prettify())  # Print the entire section for visualization\n",
    "            return section_tag\n",
    "    return None\n",
    "    \n",
    "def extract_table(section):\n",
    "    # print(\"section:\", section)\n",
    "    table_data = []\n",
    "    tables = section.find_all('table')\n",
    "    # print(\"table:\", table)\n",
    "    for table in tables:\n",
    "        if table:\n",
    "            headers = [th.get_text(strip=True) for th in table.find_all('th')]\n",
    "            rows = table.find_all('tr')[1:]  # Skip header row\n",
    "            for row in rows:\n",
    "                cols = row.find_all('td')\n",
    "                # row_data = {headers[i]: cols[i].get_text(strip=True) for i in range(len(headers))}\n",
    "                row_data = {headers[i]: cols[i].get_text(separator=' ', strip=True) for i in range(len(headers))}\n",
    "                table_data.append(row_data)\n",
    "    return table_data\n",
    "    \n",
    "# Helper function to normalize whitespace in a string\n",
    "def normalize_whitespace(text):\n",
    "    # Replace multiple spaces and newlines with a single space\n",
    "    return re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "# Function to extract paragraphs before a section with a specific id and ensure spaces around <a> and <code> elements\n",
    "def extract_paragraphs_before(section, stop_section_id):\n",
    "    paragraphs = []\n",
    "    \n",
    "    for element in section.find_all(['p', 'h3'], recursive=False):\n",
    "        # Stop if we encounter the sub-section (like \"Parameters\")\n",
    "        if element.name == 'h3' and stop_section_id in element.get('id', ''):\n",
    "            break\n",
    "        if element.name == 'p':\n",
    "            # Rebuild the paragraph's text, ensuring spaces around <a> and <code> tags\n",
    "            paragraph_text = []\n",
    "            for content in element.children:\n",
    "                \n",
    "                if content.name in ['a', 'code']:\n",
    "                    paragraph_text.append(f\" {content.get_text(strip=True)} \")\n",
    "                    # print(content)\n",
    "                else:\n",
    "                    paragraph_text.append(content if isinstance(content, str) else content.get_text(strip=True))\n",
    "                    # print(paragraph_text[-1])\n",
    "            \n",
    "            paragraphs.append(normalize_whitespace(''.join(paragraph_text)))\n",
    "    \n",
    "    return paragraphs\n",
    "    \n",
    "def make_parameters_for_TOML(tool_info):\n",
    "    lines = []\n",
    "    # for parameter in tool_info['basic_parameters']:\n",
    "    #     line = f\"{parameter['Name']}: {parameter['Description'].replace('\\n', '')}. Type: {parameter['Type']}\"\n",
    "    #     lines.append(line)\n",
    "        \n",
    "    # for parameter in tool_info['advanced_parameters']:\n",
    "    #     line = f\"{parameter['Name']}: {parameter['Description'].replace('\\n', '')}. Type: {parameter['Type']}\"\n",
    "    #     lines.append(line)\n",
    "\n",
    "    for parameter in tool_info['parameters']:\n",
    "        line = f\"{parameter['Name']}: {parameter['Label'].replace('\\n', '')}. {parameter['Description'].replace('\\n', '')}. Type: {parameter['Type']}\"\n",
    "        lines.append(line)\n",
    "    \n",
    "    para_str = \"\\n\".join(lines)\n",
    "    return para_str\n",
    "\n",
    "def make_outputs_for_TOML(tool_info):\n",
    "    lines = []\n",
    "    for output in tool_info['outputs']:\n",
    "        try:\n",
    "            line = f\"{output['Name']}: {output['Label'].replace('\\n', '')}. {output['Description'].replace('\\n', '')}. Type: {output['Type']}\"\n",
    "            lines.append(line)\n",
    "        except Exception as e:\n",
    "            print(\"Error in make_outputs_for_TOML():\", e)\n",
    "    \n",
    "    para_str = \"\\n\".join(lines)\n",
    "    return para_str\n",
    "def make_TOML_file(tool_info, fname):\n",
    "    tool_toml = {}\n",
    "    tool_toml['tool_ID'] = tool_info['algorithm_id']\n",
    "    tool_toml['tool_name'] = tool_info['tool_name']    \n",
    "    tool_toml['brief_description'] = tool_info['brief_description']\n",
    "    tool_toml['full_description'] = '\\n'.join(tool_info['paragraphs'])\n",
    "    tool_toml['parameters'] = make_parameters_for_TOML(tool_info)\n",
    "    tool_toml['outputs'] = make_outputs_for_TOML(tool_info)\n",
    "    tool_toml['code_example'] = \"\"\n",
    "    with open(fname, 'w', encoding='utf-8') as f:  # charmap' codec can't encode character\n",
    "        toml_str = toml.dump(tool_toml, f)\n",
    "        \n",
    "    # toml_str = toml.dumps(tool_toml)\n",
    "    return toml_str\n",
    "    \n",
    "def extract_tool_info(section):\n",
    "\n",
    "    tool_info = {}\n",
    "    section_id = section.get('id')\n",
    "    # print(\"section_id:\", section_id)\n",
    "    \n",
    "    h2 = section.find(\"h2\")\n",
    "    \n",
    "    if h2:  # Check if an h2 element was found\n",
    "\n",
    "        paragraph = section.find(\"p\")\n",
    "        if paragraph:\n",
    "            paragraphs = extract_paragraphs_before(section, 'parameters')\n",
    " \n",
    "            if len(paragraphs) > 0:\n",
    "                tool_info['brief_description'] = paragraphs[0]\n",
    "                # print(\"Tool description:\", tool_info['brief_description'])  \n",
    "            else: \n",
    "                tool_info['brief_description'] = \"\"\n",
    "            tool_info['tool_name'] = h2.get_text(strip=True)[:-1].split(\".\")[-1] \n",
    "            tool_info['paragraphs'] = paragraphs\n",
    "  \n",
    "        algorithm_id = None \n",
    "        python_code_snippet = None\n",
    "        \n",
    "        python_code_section = get_section_by_heading(section, 'h3', 'Python code')\n",
    "        if python_code_section: \n",
    "            algorithm_id = python_code_section.find('code').get_text(strip=True)\n",
    "            if not algorithm_id:\n",
    "                return tool_info\n",
    "            # print(\"algorithm_id:\", algorithm_id) \n",
    "            pre_tag = python_code_section.find('pre')\n",
    "            # print(\"python_code_section:\", python_code_section)\n",
    "            if pre_tag:\n",
    "                python_code_snippet = pre_tag.get_text()\n",
    "            # print(\"algorithm_id:\", algorithm_id) \n",
    "\n",
    "        # store algorithm_id\n",
    "        tool_info['algorithm_id'] = algorithm_id\n",
    "        tool_info['python_code_snippet'] = python_code_snippet\n",
    "\n",
    "        paremeters_section = get_section_by_heading(section, 'h3', 'Parameters')\n",
    "        if paremeters_section:\n",
    "            # print(\"paremeters_section:\", paremeters_section)\n",
    "            # basic_parameters_section = section.find('section', id='basic-parameters')   # only for 28.1.15. Raster analysis \n",
    "            # advanced_parameters_section = section.find('section', id='advanced-parameters') # only for 28.1.15. Raster analysis\n",
    "            \n",
    "            \n",
    "            # basic_parameters = extract_table(basic_parameters_section) if basic_parameters_section else []  # only for 28.1.15. Raster analysis\n",
    "            # advanced_parameters = extract_table(advanced_parameters_section) if advanced_parameters_section else []  # only for 28.1.15. Raster analysis\n",
    "            parameters = extract_table(paremeters_section) if paremeters_section else [] \n",
    "            # print(\"parameters:\", parameters)\n",
    "\n",
    "            # tool_info['basic_parameters'] = basic_parameters   # only for 28.1.15. Raster analysis\n",
    "            # tool_info['advanced_parameters'] = advanced_parameters   # only for 28.1.15. Raster analysis\n",
    "            tool_info['parameters'] = parameters\n",
    "            \n",
    "\n",
    "        outputs_section = get_section_by_heading(section, 'h3', 'Outputs')\n",
    "        if outputs_section:\n",
    "            outputs = extract_table(outputs_section) if outputs_section else []\n",
    "            tool_info['outputs'] = outputs\n",
    "            # print(\"outputs:\", outputs)\n",
    "\n",
    "        # print(tool_info)\n",
    "        # print(\"Tool description:\", tool_info['brief_description'])  \n",
    "        return tool_info\n",
    "    else:\n",
    "        # print(\"No h2 found in this section.\")\n",
    "        pass\n",
    "        \n",
    "    return tool_info\n",
    "\n",
    "\n",
    "save_dir = r'D:\\OneDrive_PSU\\OneDrive - The Pennsylvania State University\\Research_doc\\LLM_Geo\\QGIS_plugin\\toml'\n",
    "\n",
    "count = 0\n",
    "\n",
    "for section in sections[2:]:\n",
    "    try:\n",
    "        tool_info = extract_tool_info(section)    \n",
    "        tool_name = tool_info['algorithm_id'].replace(\":\", \"_\")\n",
    "        \n",
    "        fname = os.path.join(save_dir, f\"{tool_name}.toml\")\n",
    "        toml_str = make_TOML_file(tool_info, fname)\n",
    "        # print(\"fname:\", fname)\n",
    "        count += 1\n",
    "\n",
    "        print(f\"{count} tool_name:\", tool_name)\n",
    "\n",
    "    except Exception as e:\n",
    "\n",
    "        print(\"error:\", e)\n",
    "        pass\n",
    "\n",
    "    # if count > 0: \n",
    "    #     break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51091df-db50-4a99-9626-34a1735773b9",
   "metadata": {},
   "source": [
    "## CODE SAMPLE INTEGRATION AND REFORMATTING TOML FILE"
   ]
  },
  {
   "cell_type": "code",
   "id": "004c2705-5d63-479f-af53-9de7ea208792",
   "metadata": {},
   "source": [
    "# ! pip install tomllib\n",
    "# ! pip install tomli_w\n",
    "# ! pip install langchain_openai"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "cae98873-c76a-440f-8fcb-7ae8b4608ad0",
   "metadata": {},
   "source": [
    "import asyncio\n",
    "import os\n",
    "import re\n",
    "import tomllib\n",
    "# import tomli_w\n",
    "from langchain_openai import ChatOpenAI\n",
    "import QGIS_tool_creation_Helper"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ec61a164-ee32-40d0-815e-93380d003868",
   "metadata": {},
   "source": [
    "import asyncio\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import tomllib\n",
    "import tomli_w\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "\n",
    "# Get the directory of the current script\n",
    "current_script_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "# Add the directory to sys.path\n",
    "if current_script_dir not in sys.path:\n",
    "    sys.path.append(current_script_dir)\n",
    "\n",
    "import  QGIS_tool_creation_Helper as Helper\n",
    "\n",
    "\n",
    "OpenAI_key = Helper.get_OpenAI_key()\n",
    "\n",
    "\n",
    "# Tools_Documentation_dir = r\"D:\\Onedrive\\OneDrive - The Pennsylvania State University\\PhD Work\\SpatialAnalysisAgent_Reasearch\\Plugin\\toml\\TOML_10\"\n",
    "Tools_Documentation_dir = r\"D:\\Onedrive\\OneDrive - The Pennsylvania State University\\PhD Work\\SpatialAnalysisAgent_Reasearch\\Plugin\\toml\\TOML2_30\"\n",
    "\n",
    "def tool_documentation_collection(tool_ID, tool_dir=Tools_Documentation_dir):\n",
    "    tool_file = os.path.join(tool_dir, f'{tool_ID}.toml')\n",
    "\n",
    "    # Check if the file exists\n",
    "    if not os.path.exists(tool_file):\n",
    "        return \"\"\n",
    "\n",
    "    with open(tool_file, \"rb\") as f:\n",
    "        tool = tomllib.load(f)\n",
    "    tool_parameter_str = tool['parameters']\n",
    "    algorithm_id = tool['tool_ID']\n",
    "    # algorithm_id = \"qgis:buffer\"\n",
    "\n",
    "    tool_parameter_lines = tool_parameter_str.strip().split('\\n')\n",
    "    numbered_tool_parameter_str = ''\n",
    "    for idx, line in enumerate(tool_parameter_lines):\n",
    "        line = line.strip(' ')\n",
    "        numbered_tool_parameter_str += f\"{idx + 1}. {line}\\n\"\n",
    "\n",
    "    return numbered_tool_parameter_str, algorithm_id\n",
    "\n",
    "\n",
    "\n",
    "def append_code_to_toml(tool_ID, code_sample, tool_dir=Tools_Documentation_dir):\n",
    "    tool_file = os.path.join(tool_dir, f'{tool_ID}.toml')\n",
    "\n",
    "    # Check if the file exists\n",
    "    if not os.path.exists(tool_file):\n",
    "        print(f\"TOML file for tool {tool_ID} does not exist.\")\n",
    "        return\n",
    "\n",
    "    # Load the existing TOML file\n",
    "    with open(tool_file, \"rb\") as f:\n",
    "        tool_data = tomllib.load(f)\n",
    "\n",
    "    # # Replace the sample code in the code_example section if it exists, otherwise add it\n",
    "    # tool_data['code_example'] = code_sample\n",
    "\n",
    "    # Append the sample code to the code_example section\n",
    "    if 'code_example' in tool_data:\n",
    "        tool_data['code_example'] += f\"\\n{code_sample}\"\n",
    "    else:\n",
    "        tool_data['code_example'] = code_sample\n",
    "\n",
    "    # Write the updated content back to the file using tomli_w\n",
    "    with open(tool_file, \"wb\") as f:\n",
    "        tomli_w.dump(tool_data, f)\n",
    "\n",
    "\n",
    "def formatting_toml_file(tool_ID, tool_dir=Tools_Documentation_dir):\n",
    "    #file_path = r\"D:\\Onedrive\\OneDrive - The Pennsylvania State University\\PhD Work\\SpatialAnalysisAgent_Reasearch\\Plugin\\toml\\toml\\gdal_slope.toml\"\n",
    "\n",
    "    tool_file = os.path.join(tool_dir, f'{tool_ID}.toml')\n",
    "    with open(tool_file, 'r', encoding = 'utf-8') as file:\n",
    "        # tool = tomllib.load(f)\n",
    "        # tool_parameter_str = tool['parameters']\n",
    "        toml_content = file.read()\n",
    "\n",
    "    # Function to replace single quotes with triple quotes for specific sections\n",
    "    def replace_single_with_triple_quotes(section_name, content):\n",
    "        # Pattern to match the section content that uses single quotes\n",
    "        pattern = rf'({section_name}\\s*=\\s*)\\\"(.*?)\\\"'\n",
    "        # Replace with triple quotes\n",
    "        return re.sub(pattern, r'\\1\"\"\"\\2\"\"\"', content, flags=re.DOTALL)\n",
    "\n",
    "    # Sections that need to be reformatted\n",
    "    sections_to_format = ['brief_description', 'full_description', 'parameters', 'code_example']\n",
    "\n",
    "    # Apply reformatting to each section\n",
    "    for section in sections_to_format:\n",
    "        toml_content = replace_single_with_triple_quotes(section, toml_content)\n",
    "\n",
    "\n",
    "    # Replace occurrences of `n\\` (escaped newline in TOML) with proper multiline format\n",
    "    # Specifically, we will place strings in between triple double-quotes for basic multiline handling\n",
    "    updated_code_example = toml_content.replace('\\\\n', '\\n')\n",
    "\n",
    "    # Write the updated content back into the file\n",
    "    # updated_file_path = r'D:\\Onedrive\\OneDrive - The Pennsylvania State University\\PhD Work\\SpatialAnalysisAgent_Reasearch\\Plugin\\toml\\toml\\gdal_slope.toml'\n",
    "    with open(tool_file, 'w', encoding='utf-8') as updated_file:\n",
    "        updated_file.write(updated_code_example)\n",
    "\n",
    "def process_toml_files_in_directory(directory):\n",
    "    for file_name in os.listdir(directory):\n",
    "        if file_name.endswith(\".toml\"):\n",
    "            tool_file_name = file_name.split(\".\")[0]\n",
    "            numbered_tool_parameter_str, algorithm_id = tool_documentation_collection(tool_ID = tool_file_name)\n",
    "            Tooldoc_prompt_str = Helper.create_CodeSample_prompt(tool_doc=numbered_tool_parameter_str, algorithm_id=algorithm_id)\n",
    "\n",
    "            # Generate code sample using OpenAI model\n",
    "            OpenAI_key = Helper.get_OpenAI_key()\n",
    "\n",
    "            model = ChatOpenAI(api_key=OpenAI_key, model=\"gpt-4o\", temperature=1)\n",
    "            CodeSample_prompt_str_chunks = asyncio.run(Helper.fetch_chunks(model, Tooldoc_prompt_str))\n",
    "            LLM_reply_str = Helper.convert_chunks_to_str(chunks=CodeSample_prompt_str_chunks)\n",
    "\n",
    "            # Extract Python code and clean it\n",
    "            if 'python' in LLM_reply_str:\n",
    "                sample_code = LLM_reply_str.split('python', 1)[1].strip()\n",
    "            sample_code = sample_code.replace(\"\\\\n\", \"\\n\")\n",
    "\n",
    "            # Append the sample code to the TOML file\n",
    "            append_code_to_toml(tool_ID=tool_file_name, code_sample=sample_code)\n",
    "\n",
    "            # Reformat the TOML file for multiline strings\n",
    "            formatting_toml_file(tool_ID =tool_file_name)\n",
    "\n",
    "            print(f\"Processed file: {tool_file_name}.toml\")\n",
    "\n",
    "# Run the processing function for all TOML files in the directory\n",
    "process_toml_files_in_directory(Tools_Documentation_dir)"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
